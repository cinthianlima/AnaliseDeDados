{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fbbdc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from statisticaltools import InterCumulSamp\n",
    "from statisticaltools import Statisticaltools1\n",
    "from statisticaltools import Statisticaltools2\n",
    "from scipy import special \n",
    "import statistics\n",
    "pi = np.pi\n",
    "exp = np.exp\n",
    "Erf = special.erf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feb9d865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição uniforme\n",
    "\n",
    "# uniform = np.random.uniform(0,1,n) pontos da distribuição uniforme\n",
    "\n",
    "#Distribuição normal\n",
    "\n",
    "#Função gaussiana:\n",
    "def gauss (x):\n",
    "    g =[]\n",
    "        \n",
    "    for j in range(0,len(x)): \n",
    "                \n",
    "        g_i =  (1 / ( sigma * pow((2*pi),0.5)))* exp( -0.5 * pow ((x[j] - mi_gauss) / sigma, 2.0))\n",
    "        \n",
    "        g.append(g_i)\n",
    "    return g\n",
    "\n",
    "\n",
    "# Terceira Distribuição\n",
    "\n",
    "def dist3 (x):\n",
    "    g =[]\n",
    "    for j in range(0,len(x)): \n",
    "        g_j =  (1 / ( sigma * pow((2*pi),0.5)))* exp( -0.5 * pow (((x[j] - mi) / sigma), 2.0))\n",
    "        g_i=  (1 / ( sigma * pow((2*pi),0.5)))* exp( -0.5 * pow (((x[j] + mi) / sigma), 2.0))\n",
    "        a = Erf(mi / pow(2*sigma, 0.5))\n",
    "        \n",
    "        d = (g_j - g_i) / a\n",
    "                \n",
    "        g.append(d)\n",
    "        \n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bee67a0",
   "metadata": {},
   "source": [
    "## Cálculo dos estimadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a0f9132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants:\n",
    "sigma = 1.0\n",
    "mi = 4\n",
    "mi_gauss = 0.0\n",
    "\n",
    "#Range and points:\n",
    "n = 100 #number of points\n",
    "\n",
    "#Spaces\n",
    "x = np.linspace(-5, 5.0, num=n)\n",
    "x_dist3 = np.linspace(1,10,num=n)\n",
    "s_list =np.random.uniform(0.0, 1.0, n)\n",
    "\n",
    "# Uniform:\n",
    "uniform = np.random.uniform(0,1,n)\n",
    "uniform_obj = Statisticaltools1(uniform)\n",
    "\n",
    "# Normal:\n",
    "normal = gauss(x)\n",
    "normal_dist = InterCumulSamp(normal, x)\n",
    "normal_points = normal_dist.sampler_list_points(s_list)\n",
    "normal_obj = Statisticaltools1(normal_points)\n",
    "\n",
    "#Distribuição 3:\n",
    "dist_3 = dist3 (x_dist3)\n",
    "terceira_dist = InterCumulSamp(dist_3, x_dist3)\n",
    "ter_points = terceira_dist.sampler_list_points(s_list)\n",
    "ter_obj = Statisticaltools1(ter_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc074a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30618/4221252163.py:45: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  m2_est5 = (multip(normal_points)) ** (1/len(normal_points))\n"
     ]
    }
   ],
   "source": [
    "#Estimador 1\n",
    "soma1 = uniform_obj.soma()\n",
    "soma2 = normal_obj.soma()\n",
    "soma3 = ter_obj.soma()\n",
    "\n",
    "m1_est1 = soma1/len(uniform)\n",
    "m2_est1 = soma2/len(normal_points)\n",
    "m3_est1 = soma3/len(ter_points)\n",
    "\n",
    "#Estimador 2\n",
    "obj1 = []\n",
    "obj2 = []\n",
    "obj3 = []\n",
    "for i in range(0,9):\n",
    "    obj1.append(uniform[i])\n",
    "    obj2.append(normal_points[i])\n",
    "    obj3.append(ter_points[i])\n",
    "\n",
    "o1 = Statisticaltools1(obj1)\n",
    "o2 = Statisticaltools1(obj2)\n",
    "o3 = Statisticaltools1(obj3)\n",
    "\n",
    "m1_est2 = (o1.soma())/10\n",
    "m2_est2 = (o2.soma())/10\n",
    "m3_est2 = (o3.soma())/10\n",
    "\n",
    "#Estimador 3\n",
    "m1_est3 = soma1/(len(uniform) - 1)\n",
    "m2_est3 = soma2/(len(normal_points)- 1)\n",
    "m3_est3 = soma3/(len(ter_points) - 1)\n",
    "\n",
    "#Estimador 4\n",
    "m1_est4 = 1.8\n",
    "m2_est4 = 1.8\n",
    "m3_est4 = 1.8\n",
    "\n",
    "#Estimador 5\n",
    "def multip(list):\n",
    "    k=1\n",
    "    for s in list:\n",
    "        k = k*s\n",
    "    return(k)\n",
    "\n",
    "m1_est5 = (multip(uniform)) ** (1/len(uniform))\n",
    "m2_est5 = (multip(normal_points)) ** (1/len(normal_points))\n",
    "m3_est5 = (multip(ter_points)) ** (1/len(ter_points))\n",
    "\n",
    "#Estimador 6\n",
    "m1_est6 = statistics.mode(uniform)\n",
    "m2_est6 = statistics.mode(normal_points)\n",
    "m3_est6 = statistics.mode(ter_points)\n",
    "\n",
    "#Estimador 7\n",
    "m1_est7 = (min(uniform) + max(uniform)) / 2\n",
    "m2_est7 = (min(normal_points) + max(normal_points)) / 2\n",
    "m3_est7 = (min(ter_points) + max(ter_points)) / 2\n",
    "\n",
    "#Estimador 8\n",
    "def som2(list):\n",
    "    k=0\n",
    "    for s in range(0, n -1, 2):\n",
    "        k = k + list[s+1]\n",
    "    return(k)\n",
    "\n",
    "som1 = som2(uniform)\n",
    "som2 = som2(normal_points)\n",
    "#som3 = som2(ter_points)\n",
    "\n",
    "def estimador8(soma,list):\n",
    "    if (len(list)%2) == 0:\n",
    "        est = soma / (len(list) / 2)\n",
    "\n",
    "    else:\n",
    "        est = soma / ((len(list) - 1) / 2)\n",
    "    return (est)\n",
    "\n",
    "m1_est8 = estimador8(som1,uniform)\n",
    "m2_est8 = estimador8(som2,normal_points)\n",
    "#m3_est8 = estimador8(som3,ter_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f945157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lista_estimadores = [m1_est1, m2_est1, m3_est1, m1_est2, m2_est2, m3_est2,\n",
    "                        m1_est3, m2_est3, m3_est3, m1_est4, m2_est4, m3_est4,\n",
    "                        m1_est5, m2_est5, m3_est5, m1_est6, m2_est6, m3_est6,\n",
    "                        m1_est7, m2_est7, m3_est7, m1_est8, m2_est8, 0]\n",
    "\n",
    "\n",
    "Lista_medias = [uniform_obj.media_aritmetica(), normal_obj.media_aritmetica(), ter_obj.media_aritmetica()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e802a573",
   "metadata": {},
   "source": [
    "## Teste de consistência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efe234a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consistencia\n",
    "teste_c_uniform=[]\n",
    "teste_c_normal=[]\n",
    "teste_c_terceira=[]\n",
    "for i in range(0, len(Lista_estimadores) - 2, 3):\n",
    "    c1 = Lista_estimadores[i] - Lista_medias[1]\n",
    "    c2 = Lista_estimadores[i+1] - Lista_medias[1]\n",
    "    c3 = Lista_estimadores[i+2] - Lista_medias[1]\n",
    "    \n",
    "    teste_c_uniform.append(c1)\n",
    "    teste_c_normal.append(c2)\n",
    "    teste_c_terceira.append(c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12cf5970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5027511954764404, 0.5438032949197168, 0.5077580383507962, 1.8070737509152064, 0.3915013045209936, 0.17084040707882922, 0.5048397346765591, 0.5036302211043442]\n"
     ]
    }
   ],
   "source": [
    "print(teste_c_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b0916ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, -0.2758540305638765, -7.145202944652731e-05, 1.8070737509152064, nan, 0.5372966703154912, 0.17339395900061963, -0.05199141801757807]\n"
     ]
    }
   ],
   "source": [
    "print(teste_c_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f6934bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.010153164289074, 3.3290989170754957, 4.050588309878709, 1.8070737509152064, 3.8703802583486806, 4.540753307225722, 4.336327732710316, 0.0070737509152062564]\n"
     ]
    }
   ],
   "source": [
    "print(teste_c_terceira)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a842646",
   "metadata": {},
   "source": [
    "## Teste de viés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8e3d691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30618/1741441290.py:79: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  m2_est5 = (multip(normal_points)) ** (1/len(normal_points))\n"
     ]
    }
   ],
   "source": [
    "# Viés\n",
    "\n",
    "#Calculando os estimadores h vezes\n",
    "\n",
    "Lista_calc_estimadores = []\n",
    "h =1000\n",
    "for q in range(h):\n",
    "    #Spaces\n",
    "    x = np.linspace(-5, 5.0, num=n)\n",
    "    x_dist3 = np.linspace(1,10,num=n)\n",
    "    s_list =np.random.uniform(0.0, 1.0, n)\n",
    "\n",
    "    # Uniform:\n",
    "    uniform = np.random.uniform(0,1,n)\n",
    "    uniform_obj = Statisticaltools1(uniform)\n",
    "\n",
    "    # Normal:\n",
    "    normal = gauss(x)\n",
    "    normal_dist = InterCumulSamp(normal, x)\n",
    "    normal_points = normal_dist.sampler_list_points(s_list)\n",
    "    normal_obj = Statisticaltools1(normal_points)\n",
    "\n",
    "    #Distribuição 3:\n",
    "    dist_3 = dist3 (x_dist3)\n",
    "    terceira_dist = InterCumulSamp(dist_3, x_dist3)\n",
    "    ter_points = terceira_dist.sampler_list_points(s_list)\n",
    "#    ter_obj = Statisticaltools1(ter_points)\n",
    "    \n",
    "\n",
    "\n",
    "    #Estimador 1\n",
    "    soma1 = uniform_obj.soma()\n",
    "    soma2 = normal_obj.soma()\n",
    "    soma3 = ter_obj.soma()\n",
    "\n",
    "    m1_est1 = soma1/len(uniform)\n",
    "    m2_est1 = soma2/len(normal_points)\n",
    "#    m3_est1 = soma3/len(ter_points)\n",
    "    \n",
    "\n",
    "    #Estimador 2\n",
    "    obj1 = []\n",
    "    obj2 = []\n",
    "    obj3 = []\n",
    "    for i in range(0,9):\n",
    "        obj1.append(uniform[i])\n",
    "        obj2.append(normal_points[i])\n",
    "        obj3.append(ter_points[i])\n",
    "\n",
    "    o1 = Statisticaltools1(obj1)\n",
    "    o2 = Statisticaltools1(obj2)\n",
    "#    o3 = Statisticaltools1(obj3)\n",
    "\n",
    "    m1_est2 = (o1.soma())/10\n",
    "    m2_est2 = (o2.soma())/10\n",
    "#    m3_est2 = (o3.soma())/10\n",
    "\n",
    "\n",
    "    #Estimador 3\n",
    "    m1_est3 = soma1/(len(uniform) - 1)\n",
    "    m2_est3 = soma2/(len(normal_points)- 1)\n",
    "#    m3_est3 = soma3/(len(ter_points) - 1)\n",
    "\n",
    "\n",
    "    #Estimador 4\n",
    "    m1_est4 = 1.8\n",
    "    m2_est4 = 1.8\n",
    "#    m3_est4 = 1.8\n",
    "\n",
    "    \n",
    "    #Estimador 5\n",
    "    def multip(list):\n",
    "        k=1\n",
    "        for s in list:\n",
    "            k = k*s\n",
    "        return(k)\n",
    "\n",
    "    m1_est5 = (multip(uniform)) ** (1/len(uniform))\n",
    "    m2_est5 = (multip(normal_points)) ** (1/len(normal_points))\n",
    "#    m3_est5 = (multip(ter_points)) ** (1/len(ter_points))\n",
    "\n",
    "\n",
    "    \n",
    "    #Estimador 6\n",
    "    m1_est6 = statistics.mode(uniform)\n",
    "    m2_est6 = statistics.mode(normal_points)\n",
    "#    m3_est6 = statistics.mode(ter_points)\n",
    "\n",
    "    \n",
    "    #Estimador 7\n",
    "    m1_est7 = (min(uniform) + max(uniform)) / 2\n",
    "    m2_est7 = (min(normal_points) + max(normal_points)) / 2\n",
    "#    m3_est7 = (min(ter_points) + max(ter_points)) / 2\n",
    "\n",
    "    \n",
    "    #Estimador 8\n",
    "    def som2(list):\n",
    "        k=0\n",
    "        for s in range(0, n -1, 2):\n",
    "            k = k + list[s+1]\n",
    "        return(k)\n",
    "\n",
    "    som1 = som2(uniform)\n",
    "    som2 = som2(normal_points)\n",
    "#    som3 = som2(ter_points)\n",
    "\n",
    "    def estimador8(soma,list):\n",
    "        if (len(list)%2) == 0:\n",
    "            est = soma / (len(list) / 2)\n",
    "\n",
    "        else:\n",
    "            est = soma / ((len(list) - 1) / 2)\n",
    "        return (est)\n",
    "\n",
    "    m1_est8 = estimador8(som1,uniform)\n",
    "    m2_est8 = estimador8(som2,normal_points)\n",
    "#    m3_est8 = estimador8(som3,ter_points)\n",
    "   \n",
    "    Lista_calc_estimadores.append((m1_est1, m2_est1, m3_est1, m1_est2, m2_est2, m3_est2,\n",
    "                                  m1_est3, m2_est3, m3_est3, m1_est4, m2_est4, m3_est4,\n",
    "                                  m1_est5, m2_est5, m3_est5, m1_est6, m2_est6, m3_est6,\n",
    "                                  m1_est7, m2_est7, m3_est7, m1_est8, m2_est8, 0))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe2f5c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tirando a média de cada estimador\n",
    "\n",
    "medias_est =[]\n",
    "for j in range (0,24):\n",
    "    \n",
    "    l =[]\n",
    "    for i in range(0,h):\n",
    "        li = Lista_calc_estimadores[i][j]\n",
    "        l.append(li)\n",
    "    \n",
    "    l_obj = Statisticaltools1(l)\n",
    "    \n",
    "\n",
    "    l_media = l_obj.media_aritmetica()\n",
    "    medias_est.append(l_media)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dbb76c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viés\n",
    "\n",
    "teste_v_uniform=[]\n",
    "teste_v_normal=[]\n",
    "# teste_c_terceira=[]\n",
    "for i in range(0, len(medias_est)-1, 3):\n",
    "    v1 = medias_est[i] - Lista_medias[1]\n",
    "    v2 = medias_est[i+1] - Lista_medias[1]\n",
    "#    v3 = medias_est[i+2] - Lista_medias[1]\n",
    "    \n",
    "    teste_v_uniform.append(v1)\n",
    "    teste_v_normal.append(v2)\n",
    "#    teste_c_terceira.append(v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "010126e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5072285694481604, 0.45982166597618446, 0.5122806383222311, 1.8070737509151762, 0.3770239008937499, 0.5076287885018631, 0.5074427552063546, 0.5064607355426058]\n"
     ]
    }
   ],
   "source": [
    "print(teste_v_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b4d2d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0060381517175717506, 0.010281753473090603, 0.006027691119615843, 1.8070737509151762, nan, 0.01295227970185008, 0.0023609780144732175, 0.009850229860411692]\n"
     ]
    }
   ],
   "source": [
    "print(teste_v_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18d6345",
   "metadata": {},
   "source": [
    "## Teste de eficiência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7558d2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eficiência\n",
    "\n",
    "#Fazendo a variância de cada estimador calculado h vezes\n",
    "\n",
    "variancias_est =[]\n",
    "for j in range (0,24):\n",
    "    \n",
    "    l =[]\n",
    "    for i in range(0,h):\n",
    "        li = Lista_calc_estimadores[i][j]\n",
    "        l.append(li)\n",
    "    \n",
    "    l_obj = Statisticaltools1(l)\n",
    "    \n",
    "\n",
    "    l_variance = l_obj.variance()\n",
    "    variancias_est.append(l_variance)\n",
    "\n",
    "teste_e_uniform = []\n",
    "teste_e_normal = []\n",
    "teste_e_dist3 = []\n",
    "for i in range(0, len(variancias_est)-2, 3):\n",
    "    t1 = variancias_est[i]\n",
    "    t2 = variancias_est[i+1]\n",
    "    t3 = [i+2]\n",
    "\n",
    "    teste_e_uniform.append(t1)\n",
    "    teste_e_normal.append(t2)\n",
    "    teste_e_dist3.append(t3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a69ad5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0008813455843472274, 0.007143002251228698, 0.0008992404696941405, 9.119232064354896e-28, 0.0014180190148920444, 0.08617056046944356, 4.796303974530878e-05, 0.0017790920782647197]\n"
     ]
    }
   ],
   "source": [
    "print(teste_e_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e19dfa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.009262193969147143, 0.09012871936385468, 0.009450254024229304, 9.119232064354896e-28, nan, 1.0125729892795368, 0.09570641699640746, 0.018181699646684327]\n"
     ]
    }
   ],
   "source": [
    "print(teste_e_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd81c41",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c5baac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
